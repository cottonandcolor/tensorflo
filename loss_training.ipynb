{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap #Uncomment these if you have installed matplotlib (pip3 install matplotlib)\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"x_circles.data\",'rb') as f:\n",
    "    x = np.load(f)\n",
    "with open(\"y_circles.data\",'rb') as f:\n",
    "    y = np.load(f).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100, 2), (100, 1))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x116935750>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEACAYAAABVtcpZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCAghRItRERBCiBajIiCEEC3mH6zFvSNyQQKWAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116889990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scatter(x[:,0], x[:,1], c=y, cmap= ListedColormap(['#FF0000', '#0000FF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self, batchsize, xsize, optimizer=tf.train.GradientDescentOptimizer):\n",
    "        self.learning_rate = tf.Variable(0.0, dtype=tf.float32, trainable=False)\n",
    "        self.x = tf.placeholder(shape=(batchsize, xsize), dtype=tf.float32, name=\"x\")\n",
    "        self.y = tf.placeholder(shape=(batchsize,1), dtype=tf.float32, name=\"y\")\n",
    "        w = tf.get_variable(\"w\", shape=(xsize,1))\n",
    "        b = tf.get_variable(\"b\", shape=(1))\n",
    "        logit = tf.add(tf.matmul(self.x,w),b) #Broadcast\n",
    "        self.proba = tf.sigmoid(logit)\n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=self.y)) \n",
    "        self.train = optimizer(self.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable LR/w already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-77d2899a4887>\", line 6, in __init__\n    w = tf.get_variable(\"w\", shape=(xsize,1))\n  File \"<ipython-input-6-a175c081b5bf>\", line 3, in <module>\n    lr = LogisticRegression(100,2)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-a175c081b5bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.05\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-77d2899a4887>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batchsize, xsize, optimizer)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_variable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Broadcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m   1047\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m       use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m   1050\u001b[0m get_variable_or_local_docstring = (\n\u001b[1;32m   1051\u001b[0m     \"\"\"%s\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    946\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m           use_resource=use_resource, custom_getter=custom_getter)\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter)\u001b[0m\n\u001b[1;32m    354\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m           validate_shape=validate_shape, use_resource=use_resource)\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    339\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m           use_resource=use_resource)\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource)\u001b[0m\n\u001b[1;32m    651\u001b[0m                          \u001b[0;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 653\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    654\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable LR/w already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"<ipython-input-5-77d2899a4887>\", line 6, in __init__\n    w = tf.get_variable(\"w\", shape=(xsize,1))\n  File \"<ipython-input-6-a175c081b5bf>\", line 3, in <module>\n    lr = LogisticRegression(100,2)\n  File \"/usr/local/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "initializer = tf.random_uniform_initializer(minval=-0.05, maxval=0.05)\n",
    "with tf.variable_scope(\"LR\", reuse=None, initializer=initializer):\n",
    "    lr = LogisticRegression(100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'LR/w:0', [2, 1]),\n",
       " (u'LR/b:0', [1]),\n",
       " (u'MLP/w:0', [2, 2]),\n",
       " (u'MLP/b:0', [2]),\n",
       " (u'MLP/w2:0', [2, 1]),\n",
       " (u'MLP/b2:0', [1]),\n",
       " (u'MLP_adam/w:0', [2, 2]),\n",
       " (u'MLP_adam/b:0', [2]),\n",
       " (u'MLP_adam/w2:0', [2, 1]),\n",
       " (u'MLP_adam/b2:0', [1]),\n",
       " (u'MLP3/w:0', [2, 2]),\n",
       " (u'MLP3/b:0', [2]),\n",
       " (u'MLP3/w2:0', [2, 2]),\n",
       " (u'MLP3/b2:0', [2]),\n",
       " (u'MLP3/w3:0', [2, 1]),\n",
       " (u'MLP3/b3:0', [1])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(t.name, t.get_shape().as_list()) for t in tf.trainable_variables()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer()) #Set w,b to random values from distribution\n",
    "sess.run(tf.assign(lr.learning_rate, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69330519, None]\n"
     ]
    }
   ],
   "source": [
    "output = sess.run([lr.loss, lr.train], feed_dict={lr.x:x, lr.y:y})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69329619, 0.46000000000000002)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss, proba, _ = sess.run([lr.loss, lr.proba, lr.train], feed_dict={lr.x:x, lr.y:y})\n",
    "    if i % 1000 == 0:\n",
    "        proba = sess.run(lr.proba, feed_dict={lr.x:x, lr.y:y})\n",
    "        accuracy = (np.where(proba >= 0.5, 1, 0) == y).mean()\n",
    "        print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) #Make weights random again\n",
    "sess.run(tf.assign(lr.learning_rate, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69332671, 0.60999999999999999)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n",
      "(0.69311303, 0.47999999999999998)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss, proba, _ = sess.run([lr.loss, lr.proba, lr.train], feed_dict={lr.x:x, lr.y:y})\n",
    "    accuracy = (np.where(proba >= 0.5, 1, 0) == y).mean()\n",
    "    if i % 1000 == 0:\n",
    "        print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP():\n",
    "    def __init__(self, batchsize, xsize, optimizer=tf.train.GradientDescentOptimizer):\n",
    "        self.learning_rate = tf.Variable(0.0, dtype=tf.float32, trainable=False)\n",
    "        self.x = tf.placeholder(shape=(batchsize, xsize), dtype=tf.float32, name=\"x\")\n",
    "        self.y = tf.placeholder(shape=(batchsize,1), dtype=tf.float32, name=\"y\")\n",
    "        \n",
    "        #Hidden Layer\n",
    "        w = tf.get_variable(\"w\", shape=(xsize, 2))\n",
    "        b = tf.get_variable(\"b\", shape=(2))\n",
    "        hidden = tf.sigmoid(tf.matmul(self.x,w) + b) \n",
    "        \n",
    "        w2 = tf.get_variable(\"w2\", shape=(2,1))\n",
    "        b2 = tf.get_variable(\"b2\", shape=(1))\n",
    "        logit = tf.matmul(hidden,w2) + b2\n",
    "        \n",
    "        self.proba = tf.sigmoid(logit)\n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=self.y)) \n",
    "        self.train = optimizer(self.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"MLP\", reuse=None, initializer=initializer):\n",
    "    mlp = MLP(100, 2)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.assign(mlp.learning_rate, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6931476, 0.5)\n",
      "(0.69314599, 0.5)\n",
      "(0.69314575, 0.5)\n",
      "(0.69314557, 0.52000000000000002)\n",
      "(0.69314528, 0.53000000000000003)\n",
      "(0.69314516, 0.53000000000000003)\n",
      "(0.69314486, 0.52000000000000002)\n",
      "(0.69314462, 0.53000000000000003)\n",
      "(0.69314432, 0.52000000000000002)\n",
      "(0.69314402, 0.51000000000000001)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss, proba,  _  = sess.run([mlp.loss, mlp.proba, mlp.train], feed_dict={mlp.x:x, mlp.y:y})\n",
    "    if i % 1000 == 0:\n",
    "        accuracy = (np.where(proba >= 0.5, 1, 0) == y).mean()                                                       \n",
    "        print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) #Make weights random again\n",
    "sess.run(tf.assign(mlp.learning_rate, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69323421, 0.5)\n",
      "(0.69314742, 0.47999999999999998)\n",
      "(0.69314682, 0.45000000000000001)\n",
      "(0.69314593, 0.51000000000000001)\n",
      "(0.69314402, 0.53000000000000003)\n",
      "(0.69314003, 0.52000000000000002)\n",
      "(0.693133, 0.48999999999999999)\n",
      "(0.69312316, 0.48999999999999999)\n",
      "(0.69311112, 0.48999999999999999)\n",
      "(0.69309282, 0.48999999999999999)\n",
      "(0.6930455, 0.48999999999999999)\n",
      "(0.69272965, 0.47999999999999998)\n",
      "(0.60118383, 0.72999999999999998)\n",
      "(0.48980823, 0.80000000000000004)\n",
      "(0.48427278, 0.81000000000000005)\n",
      "(0.4816356, 0.80000000000000004)\n",
      "(0.47943482, 0.79000000000000004)\n",
      "(0.47702241, 0.79000000000000004)\n",
      "(0.47438905, 0.79000000000000004)\n",
      "(0.47190312, 0.79000000000000004)\n"
     ]
    }
   ],
   "source": [
    "for i in range(20000):\n",
    "    loss, proba, _  = sess.run([mlp.loss, mlp.proba, mlp.train], feed_dict={mlp.x:x, mlp.y:y})\n",
    "    if i % 1000 == 0:\n",
    "        accuracy = (np.where(proba >= 0.5, 1, 0) == y).mean()                                                       \n",
    "        print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"MLP_adam\", reuse=None, initializer=initializer):\n",
    "    mlp = MLP(100, 2, optimizer=tf.train.AdamOptimizer)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.assign(mlp.learning_rate,0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69314766, 0.5)\n",
      "(0.6472404, 0.67000000000000004)\n",
      "(0.59124547, 0.66000000000000003)\n",
      "(0.56631339, 0.68000000000000005)\n",
      "(0.52019483, 0.75)\n",
      "(0.50108832, 0.79000000000000004)\n",
      "(0.4929058, 0.81000000000000005)\n",
      "(0.48796532, 0.81000000000000005)\n",
      "(0.48499689, 0.81000000000000005)\n",
      "(0.48293218, 0.80000000000000004)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss, proba,  _  = sess.run([mlp.loss, mlp.proba, mlp.train], feed_dict={mlp.x:x, mlp.y:y}) \n",
    "    if i % 1000 == 0:\n",
    "        accuracy = (np.where(proba >= 0.5, 1, 0) == y).mean()                                                       \n",
    "        print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0099999998"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer()) #Make weights random again\n",
    "sess.run(tf.assign(mlp.learning_rate, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69360059, 0.5)\n",
      "(0.52470893, 0.76000000000000001)\n",
      "(0.52021736, 0.76000000000000001)\n",
      "(0.51940733, 0.75)\n",
      "(0.51890546, 0.75)\n",
      "(0.51858318, 0.75)\n",
      "(0.51841646, 0.75)\n",
      "(0.51832813, 0.75)\n",
      "(0.51823694, 0.75)\n",
      "(0.51791131, 0.75)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss, proba,  _  = sess.run([mlp.loss, mlp.proba, mlp.train], feed_dict={mlp.x:x, mlp.y:y}) \n",
    "    if i % 1000 == 0:\n",
    "        accuracy = (np.where(proba >= 0.5, 1, 0) == y).mean()                                                       \n",
    "        print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Baseline optimizer: GradientDescent with starting learning rate of 0.1\n",
    "# Often the easiest optimizer out of the box: AdamOptimizer with starting learning rate of 0.001\n",
    "# To do quick checks of learning rate starting values try going up or down 10x (so check within 1.0, 0.1, 0.01)\n",
    "# Some have found Adam to learn faster, but SGD to eventually get better accuracy\n",
    "# Google state of the art Neural Machine Translation uses Adam for most of the training\n",
    "# and then finishes with some SGD (and then Reinforcement Learning!!)\n",
    "# https://arxiv.org/pdf/1609.08144v2.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
    "y = np.array([0,1,1,0]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scatter(x[:,0], x[:,1], c=y, cmap= ListedColormap(['#FF0000', '#0000FF']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MLP3():\n",
    "    def __init__(self, batchsize, xsize, optimizer=tf.train.GradientDescentOptimizer):\n",
    "        self.learning_rate = tf.Variable(0.0, dtype=tf.float32, trainable=False)\n",
    "        self.x = tf.placeholder(shape=(batchsize, xsize), dtype=tf.float32, name=\"x\")\n",
    "        self.y = tf.placeholder(shape=(batchsize,1), dtype=tf.float32, name=\"y\")\n",
    "        \n",
    "        #Hidden1\n",
    "        w = tf.get_variable(\"w\", shape=(xsize, 2))\n",
    "        b = tf.get_variable(\"b\", shape=(2))\n",
    "        hidden1 = tf.square(tf.matmul(self.x,w) + b)\n",
    "        \n",
    "        #hidden2\n",
    "        w2 = tf.get_variable(\"w2\", shape=(xsize, 2))\n",
    "        b2 = tf.get_variable(\"b2\", shape=(2))\n",
    "        hidden2 = tf.square(tf.matmul(hidden1,w2) + b2)\n",
    "        \n",
    "        w3 = tf.get_variable(\"w3\", shape=(2,1))\n",
    "        b3 = tf.get_variable(\"b3\", shape=(1))\n",
    "        logit = tf.matmul(hidden2,w3) + b3\n",
    "        \n",
    "        self.proba = tf.sigmoid(logit)\n",
    "        self.loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit, labels=self.y)) \n",
    "        self.train = optimizer(self.learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"MLP3\", reuse=False, initializer=tf.random_uniform_initializer(minval=-0.05, maxval=0.05)):\n",
    "    mlp = MLP3(None, 2, optimizer=tf.train.AdamOptimizer)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.assign(mlp.learning_rate, 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.assign(mlp.learning_rate, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.69323492, 0.5)\n",
      "(1.3768145e-06, 1.0)\n",
      "(8.702745e-07, 1.0)\n",
      "(5.1648624e-07, 1.0)\n",
      "(3.0078451e-07, 1.0)\n",
      "(1.7479486e-07, 1.0)\n",
      "(1.0221274e-07, 1.0)\n",
      "(6.0635621e-08, 1.0)\n",
      "(3.6723403e-08, 1.0)\n",
      "(2.2834023e-08, 1.0)\n"
     ]
    }
   ],
   "source": [
    "for i in range(10000):\n",
    "    loss, proba,  _  = sess.run([mlp.loss, mlp.proba, mlp.train], feed_dict={mlp.x:x, mlp.y:y}) \n",
    "    if i % 1000 == 0:\n",
    "        accuracy = (np.where(proba >= 0.5, 1, 0) == y).mean()                                                       \n",
    "        print(loss, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
